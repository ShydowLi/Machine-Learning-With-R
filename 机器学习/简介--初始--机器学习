----机器学习-----------------------------------------------------------------------------------------------

    机器学习：如果机器能够获取经验并且能利用它们，在以后的类似经验中能够提高它的表现
    学习过程：
        数据存储：利用观测值、记忆存储、提供进一步推理的事实依据
        抽象化：将数据转化为更宽泛的表示和概念
        一般化：创建知识和推理，使得形动具有新的背景
        评估：衡量学习知识，提出潜在的改进之处
        
    实践机器学习中的步骤：
        数据收集：
        数据探索和准备：特征工程
        模型训练
        模型评价
        模型改进
        
    
    模型：
        预测模型：目标特征与其他特征之间关系建立模型（有监督）----分类
        描述性模型：总结数据并获得洞察（无监督）---模式发现--购物篮分析--------聚类
        元学习算法：专注于如何更有效的学习
        
有监督模型包括：最近邻、朴素贝叶斯、决策树、分类规则学习算法、线性回归、回归树、模型树、神经网络、支持向量机
无监督模型包括：关联规则、K均值聚类
元学习算法：Bagging  Boosting  随机森林


=-----------------------------------------------------------------------------------------------------------=
注：准确类，精准类，召回率的区别
    
    准确率：指将样本正例预测为正例，样本负例预测为负例的个数占所有数量的比重
    
    精准率：精准率是针对预测结果而言，表示预测为正的样本中有多少是对的，那么预测为正就有两种可能，一种是正例预测为正例（TP），另一种是把负类预测为正类（FP）
        p=tp/(tp+fp)
        
    召回率：召回率是针对我们原来的样本而言，表示样本中的正例有多少被预测正确了，一种是原来的正例被预测为正例（top），一种是原来的正例备预测为负例（fn）
        p=tp/（tp+fn）


=------------------------------------------------------------------------------------------------------------=
注：偏差与方差的区别
    
    1、在做分类器时：出现以下4种的结果
    
                      ·1     .2     .3        .4
    训练集（error）： 1%    15%     15%      0.8% 
    测试集 (error) ： 11%    16%     30%      1%
    
    --如上图1，4两种情况中训练集的误差已经很小了，称为low bias，说明训练已经很到位了，而2，3两种情况的训练集误差很大，称为
    High bias，故偏差（bias）是用来衡量训练集和我们的最小误差的差距。
    --在1情况下，验证集相比训练集误差上升了很多，而在2情况下，虽然误差升高了，但变化并不大，所以说：方差是指测试集和训练      集的效果的差别，而不是一个绝对的值。
    --偏差（bias）：针对的是训练集与我们规定的最小误差
    --方差（variance）：针对的是训练集和测试集
    
    --上图中1属于过拟合，2属于欠拟合，3属于烂，4属于赞
    
    ==--高偏差意味着模型训练不到位，也就是欠拟合，高方差意味着模型训练过头了，过拟合了。但是过拟合一般是训练集误差很小而验     证集误差很大，如果两者都高，只能说明模型太烂。
    
    
    
    2、解决偏差与误差的问题
    
    --如果模型是高偏差（欠拟合）：
          --尝试使用更复杂更大的网络结构（增加单元数，增加层数，或者更改结构），训练更长的时间（增加迭代书）
          --当高偏差解决后，如果存在高方差：
               --收集更多的样本去训练使用，正则化手段
               --当经过以上还是高方差：说明遇到典型的超度
               --正则化：给损失函数加一个正则化项，相当于给它一个惩罚因子（惩罚项）
                    --L2正则化：(λ/2m)*sum(w^2) 即所有的参数权值（w）的平方，再乘以λ/2m（使模型变得简单） dropout  early              -stopping
                    
                    
==------------------------------------------------------------------------------------------------------------------------
     
注：相关与因果之间的区别：
                                 
  
    
    






  
        
        
        
        
   