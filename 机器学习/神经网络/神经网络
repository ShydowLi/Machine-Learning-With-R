#------黑箱方法--------神经网络和支持向量机--------------------------------------------------------

      1、黑箱方法：输入转换为输出是通过一个假想的箱子来模糊处理的，发挥作用的复杂的数学。
      学习目标：
          神经网络模仿动物大脑的结构来模拟任意函数（功能）；
          支持向量机使用多维曲面来定义特征与结果之间的关系；
          怎么样去应用于现实的世界中；
          
      2、神经网络：
          人工神经网络是对一组输入信号和一组输出信号之间的关系进行建模，使用的模型来源于人类大脑对来自感觉输入刺激是如        何反应的理解。人工神经网络同样使用神经元或者节点来处理学习问题。
          从广义上讲，神经网络可以用于几乎所有学习任务的多功能学习方法：分类、数值预测、甚至无监督的模式识别
          
          基本的理解：一个有向网络中图定义了树突接受的输入信号（变量x）和输出信号（y）之间的关系。与生物神经元一样，每        一个树突的信号都根据其重要性被加权。输入信号有细胞体求和，然后该信号根据一个用f表示的激活函数来传递。
                                   y(x)=f(sum(wi*xi))  
          权重w可以控制n个输入信号中的每一个输入对输入信号之和所做的贡献的大小。激活函数f(x)使用净总和，y（）就是输出轴        突
          
          激活函数：将神经元的组合输入信号变换成单一的输入信号，以便进一步的在网络中传播；
          网络拓扑（结构）：描述模型中神经元的数量以及层数和它们的连接方式
          训练算法：指定如何连接权重，以便减小或者增加神经元在输入信号中的比例
         
          
      3、激活函数：（阈值激活函数）
          激活函数：是指人工神经元中处理输入信息并将信息传递到整个网络的机制。
          激活函数的类型：单位跳跃激活函数，S型激活函数（比较常用），除此之外：线性激活、饱和线性激活、双曲面正切、高斯
          区分激活函数：就是输出信号的范围不同，大多在(0,1),(-1,1),(-oo,+oo)
          对于许多激活函数而言，影响输出信号的输入值范围是相对窄的（所以数据需要标准化或规范化）
          
         拓扑结构：
            层数；网络的信息是否允许向后传播；网络每一层的节点数
            拓扑结构决定了通过神经网络进行学习的复杂性，可能更大、更复杂的网络能够识别更微妙的模式和更复杂的决策边界。             但是神经网络的效能不仅是一个网络规模的函数，还取决于构成元素的组织方式。
            
            根据信息传播的方向可以分为：
                前馈网络：输入信号从一个节点到另一个节点连续传播，直至到达输出层（多层感知器）
                深度神经网络：具有多个隐藏层的神经网络
                递归网络（反馈网络）：允许信号使用循环在两个方向上传送，增加一个延迟或者短期记忆会使得递归网络有很大功                 效
                
            每一层节点数：
                输入层：输入节点数有输入数据的特征已经决定了
                输出层：输出节点数由需要建模的结果树或者结果的分类水平确定
                隐藏层：由使用者确定
        
       4、后向传播神经网络（BP神经网络）
            优点：适用于分类和数值预测；能够模拟复杂的模式；对数据的基本关系不需要做出假设
            缺点：计算量庞大，训练缓慢，很容易过度拟合
            
            在前向阶段中：神经元在从输入层到输出层的序列中被激活，沿途应用每一个神经元的权重和激活函数，一旦到达最后一             层，就会产生一个输出信号。
            在后向阶段：由前向阶段产生的输出信号与训练数据中的真实目标值进行比较，网络的输出信号与真实目标值之间的差异             产生的误差在网络中向后传播，从而修正神经元之间的连接权重，并减小将来产生的误差。
            
            梯度下降法：
            
            后向传播算法利用每一个神经元的激活函数的倒数来确定每一个输入权重方向上的梯度，因此，需要一个可微的激活函数             很重要，梯度将因为权重的改变而表明误差是如何急剧减小或者增大。该算法通过一个称为学习率的量来改变权重来使得             误差最大化的减少。学习率越大，算法试图降下的梯度就越快。
            
==---------------------------------------------------------------------------------------------------------------------   误差校正学习算法：（分类与预测）
      根据神经网络的输出误差对神经元的连接强度进行修正（也就是每一个节点的权重）。设神经网络中神经元i作为输入，神经元j
      为输出神经元，他们的连接权值为w，则权值的修正为：学习率*偏差*输出值

      误差函数：sum（【实际输出值-期望输出值】^2）
      

==---------------------------------------------------------------------------------------------------------------------
  神经网络的本质：就是人为的选择f(.)激活函数，并用训练集确定阈值和权值，使得函数F(X，β)能够更好的描述训练数据的关系。
