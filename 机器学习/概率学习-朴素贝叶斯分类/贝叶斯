-----------------概率学习——朴素贝叶斯简述-----------------------------------------------------------------------
1、朴素贝叶斯：
    概率的基本原则；
    使用R分析文本数据需要的专用方法和数据结构
    使用朴素贝叶斯分类器建立SMS垃圾短信过滤器
    
理解朴素贝叶斯：描述事件概率以及如何根据附加信息修正概率的基本原则，贝叶斯方法
    利用训练数据并根据特征取值提供的证据来计算每一个结果被观察到的概率。当分类器用于无标签数据时，分类器就会根据观测到的概率来预测新的特征最有可能属于哪一类。
    常用于：文本分类、比如垃圾邮件过滤
            在计算机网络中进行入侵检测或者异常检测
            根据一组观察到的症状，诊断身体状况
    最适用于解决：为了估计一个结果的总体概率，从众多属性中提取的信息应该被同时考虑。贝叶斯分类利用所有可获得的证据来巧妙的修正预测，如果大量特征产生的影响较小，但将它们放在一起，组合影响可能会很大。
    
        
2、贝叶斯方法的基本概念：
    贝叶斯概率理论基于这样一个思想：即一个事件或者一个可能结果的似然估计应建立在手中已有的证据之上，而证据需要经过多次试验或者事件发生的机会来得到。
    **
    1、完全相互独立事件：实验有两个不可能同时发生的结果；它的对立事件为1-p
    2、条件概率：事件A发生的情况下事件B发生的概率
              P(B|A)=P(AB)/P(A)
              p(B1∪B2/A)=P(B1/A)+P(B2/A)-P(B1B2/A)
    3、乘法定理：
              P(AB)=P(B|A)P(A)
              P(ABC)=P(C|BA)P(B|A)P(A)
              当两个事件时相互独立事件时：P(AB)=P(A)P(B)
    4、全概率与贝叶斯公式
    
       全概率：
              P(A)=P(A|B1)P(B1)+P(A|B2)P(B2)+P(A|B3)P(B3)+....+P(A|Bi)P(Bi)
       贝叶斯：
              --P(a|b)与P(b|a)的相互转化
              P(Bi|A)=P(BiA)/P(A)=P(A|Bi)P(Bi)/全概率（p(A)）          
              常用于当n=2时：
              
                        P(A)=P(A|B)P(B)+P(A|B')P(B')
                        P(B|A)=P(AB)/P(A)=P(A|B)P(B)/P(A)  --P(A)转化为以上的全概率公式
                        
              
3、朴素贝叶斯算法
    1、将贝叶斯定理应用于分类问题的简单方法，常用于文本分类应用中
    优点：简单、快速、有效，能够很好的处理噪声数据，需要训练的案例较少，很容易获得预测的估计概率值
    缺点:依赖于一个常用的错误假设：一样的重要性和独立特征，当特征大量时模型并不理想，概率估计值并不可靠
  **朴素贝叶斯假设数据集的所有特征都具有相同的重要性和独立性，假设太理想。
  **虽然朴素贝叶斯可能违背了以上的假设，但是可以很好的应用。原因在于我们最终关注的知识模型的正确率，而不是
    模型识别正确的把握，也就是：准确率>>概率，我们更关注的是概率
    
    2、拉普拉斯估计：
        给频率表中的每一个计数加上一个较小的数，保证每一个特征发生的概率为非零。一般情况下加上的数值设定为1，这样保证每     类特征的组合至少在数据中出现一次。

    3、朴素贝叶斯算法中使用数值特征
        创建类和特征值的组合构成的矩阵，每一个特征必须是分类变量。需要将数值特征值离散化。也可以自己根据实际情况创建一     个自然分类。将数值离散化总是会导致信息量的减少，因为特征的原始粒度减少为几个数目较少的类别，所以分段应该均衡，分段     越多会导致频率表数值较小，太少会受噪声数据的影响。
    
    
    
       
    
  