==----------预测数值型数据--回归方法------------------------------
    1、
    ==学习：
        --回归中使用的基本统计原则，对数值关系的和规模和强度建立模型技术
        --为一个回归模型准备数据，估计并解释一个回归模型
        --一对称为回归树和模型树的混合技术，他们适用于数值预测任务的决策树分类
        
    ==回归：
        --回归主要关注确定一个唯一的因变量和一个或多个数值型自变量之间的关系，回归最简单的形式是假设因变量和自变量之间的关系           遵循线性管线。
        --y=ax+b;确定x和y，从而使指定的直线更加适合用来反映所提供X值和Y值之间的关系
        --一般用于：根据种群和个体测得特征；量化事件及其响应之间的因果关系；给定已知的准则，确定可用来预测未来行为的模型
        
        ==--回归方法也可用于统计假设检验，根据观测数据确定假设更可能是真的还是假的。
        
    
    ==简单线性回归和多元线性回归：两种方法都是假设因变量是以一种连续的尺度测量的
        
    ==逻辑回归：对二元分类建模
    
    ==泊松回归：对整形计数数据建模
    
    ==多项逻辑回归：分类结果建模
    
    
    2、
        1、普通最小二乘法
            斜率和截距的选择要使得误差（y的预测值与y的真实值之间的垂直距离）的平方和最小，这些误差被称为残差。
                      sum(Yi-yi)^2=sum(e^2)  Yi是指预测值   yi是指真实值
            公式：
                      y=a+bX  --b=cov(x,y)/var(x)   --a=y'-bx'  --y',x'平均值
                      
        
        2、相关性
           两个变量之间的相关系数是一个数，表示两个变量服从一条直线的关系有多么的紧密。
                      p(x,y)=corr(x,y)=cov(x,y)/sd(x,y)  --即协方差/x，y的标准差
                      
                      
    3、多元线性回归
      
        1、优点：数值建模最常用的方法；几乎适用于所有数值建模任务；提供特征与结果之间的强度和大小的估计
           缺点：对数据使用很强的假设；模型必须由使用者事先指定；不能处理缺失数据；只能处理数值特征
           
           多元线性回归方程：y=α+β1X1+β2X2+.......βiXi+e   α表示截距项  e表示残差项
           
           由于截距项α是一个定值：
                             y=β0X0+β1X1+β2X2+.......βiXi+e
           将记录带入公式，我们将得到一个矩阵运算：
              Y=βX+e    此时：因变量Y是一个向量  自变量被合并为矩阵X （其中需要加上截距项为1的列） β和e都是向量
           
           接下来求解预测值与真实值之间的误差平方和最小的回归系数向量β
                    β=(X'X)-1X'Y
              
              
        
    4、回归树与模型树
       
         用于数值预测的决策树可分为两类，是分类回归树和模型树。
         回归树：基于到达叶节点的案例的平均值做出的预测
         模型树：模型树与回归树以大致相同的方式生长，但是在每个叶子节点，根据到达该节点的案例建立多元线性回归模型。
         
         优点：将决策树的优点与对数值数据建立模型结合；能自动选择特征
         缺点：需要大量的训练数据集；难以确定单个特征对于结果的影响；大型决策树变得比回归模型更难理解
         
         区别：分类决策树中，一致性（均匀性）是由熵值决定的，而在数值决策树中，一致性可以通过统计量（方差，平均值等）来                度量，一种常见的分割标准为：标准偏差减少
                                  SDR=sd(T)-sum((Ti/T)*sd(Ti))
               sd(T)表示标准差，T1...Tn是指一个特征的一次分割产生值的集合
               通过比较分割前的标准差与分够后的加权标准差来度量标准差的减少量。
               
               
                                  
            
                      
                    
                          
                      
                      
                  
                             
        
    
    
    
    
        
        
        